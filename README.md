# sitemapgenerator_public
This solution solve three problems:
* crawler
* lastmodificatecheck
* sitemap generator

It starts from main page of website and search all internal links.
After that it save hash in file and keeps last date of modificate.
The last step it creates sitemap with this information, by looking on robots file.

mb in Future will (not) modificate:
* check only important part of page
* absolute correct work with robots for Google and Yandex searchbots
* use the parameter of amount links in one sitemap

